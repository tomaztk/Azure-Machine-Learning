{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# German Credit Data Analysis\n",
        "\n",
        "Loans form an integral part of banking operations. However, not all the loans are promptly returned and hence it is important for a bank to closely monitter its loan applications.  This project is an analysis of the German credit data. It contains  details of 1000 loan applicants with 20 attributes and the classification whether an applicant is considered a Good or a Bad credit risk. \n",
        "\n",
        "In this project, the relationship between the credit risk and various attribues will be explored through basic statistical techniques, and presented through visualizations.\n",
        "\n",
        "### **Contents**\n",
        "\n",
        "1. Import data\n",
        "2. Data preparation, cleaning\n",
        "3. Exploratory data analysis\n",
        "4. Feature engineering\n",
        "5. Models\n",
        "6. Summary\n",
        "\n",
        "I will be using Python 3.8 AzureML kernel."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import data\n",
        "\n",
        "Let's begin by downloading the data from the [UCI Machine Learning repository](http://archive.ics.uci.edu/ml/about.html). "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset has been downloaded and extracted."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Preparation and Cleaning\n",
        "\n",
        "In this step, we do data preparation and cleaning, making the data suitable for subsequent analysis. \n",
        "\n",
        "**2.1 Load data into dataframe**\n",
        "\n",
        "The datafile is in `.data` format,  delimited with space, and has no headers."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data', delimiter=' ',header=None)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425460108
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(df)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425460309
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Based on the description, we name the columns.\n",
        "\n",
        "df.columns=['account_bal','duration','payment_status','purpose',\n",
        "                   'credit_amount','savings_bond_value','employed_since',\n",
        "                   'intallment_rate','sex_marital','guarantor','residence_since',\n",
        "                   'most_valuable_asset','age','concurrent_credits','type_of_housing',\n",
        "                   'number_of_existcr','job','number_of_dependents','telephone',\n",
        "                   'foreign','target']\n",
        "df= df.replace(['A11','A12','A13','A14', 'A171','A172','A173','A174','A121','A122','A123','A124'],\n",
        "                  ['neg_bal','positive_bal','positive_bal','no_acc','unskilled','unskilled','skilled','highly_skilled',\n",
        "                   'none','car','life_insurance','real_estate'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425460445
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Exploratory Data Analysis and Visualization"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries for visualizations\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "matplotlib.rcParams['font.size'] = 14\n",
        "matplotlib.rcParams['figure.figsize'] = (9, 5)\n",
        "matplotlib.rcParams['figure.facecolor'] = '#00000000'\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425460577
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Examine missing values"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check for missing values\n",
        "df.isna().any().any()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425460720
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1 Examining distribution of target column\n",
        "\n",
        "df.target.unique()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425460864
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le= LabelEncoder()\n",
        "le.fit(df.target)\n",
        "df.target=le.transform(df.target)\n",
        "df.target.head(5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425461013
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loans_good_bad=round(((df.target.value_counts()/df.target.count())*100))\n",
        "#good_bad_per\n",
        "plt.pie(loans_good_bad,labels=['Good', 'Bad'], autopct='%1.0f%%', startangle=90)\n",
        "plt.title('Percentage of Good vs. Bad loans');"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425461139
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['credit_amount','duration','age']].describe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425461272
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['credit_amount']=np.log(df['credit_amount'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425461389
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['credit_amount','duration','age']].describe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425461636
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# histograms of continues variables\n",
        "\n",
        "fig, axes = plt.subplots(1,3, figsize=(16,8))\n",
        "plt.suptitle('Histogram of continuous variables')\n",
        "axes[0].hist(df['duration'])\n",
        "axes[0].set_xlabel('No. of observations')\n",
        "axes[0].set_ylabel('Years')\n",
        "axes[0].set_title('Histogram of loan duration');\n",
        "\n",
        "axes[1].hist(df['credit_amount'])\n",
        "axes[1].set_xlabel('No. of observations')\n",
        "axes[1].set_ylabel('Credit amount (dollars)')\n",
        "axes[1].set_title('Histogram of Credit amount');\n",
        "\n",
        "axes[2].hist(df['age'])\n",
        "axes[2].set_xlabel('No. of observations')\n",
        "axes[2].set_ylabel('Age')\n",
        "axes[2].set_title('Histogram of Age');"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425461768
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# box-plots of continues variables\n",
        "\n",
        "fig, ax = plt.subplots(1,3,figsize=(20,5))\n",
        "plt.suptitle('BOX PLOTS')\n",
        "sns.boxplot(df['credit_amount'], ax=ax[0]);\n",
        "sns.boxplot(df['duration'], ax=ax[1], color='salmon');\n",
        "sns.boxplot(df['age'], ax=ax[2], color='darkviolet');"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425461890
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2 Relationship between the credit amount and repayment duration**\n",
        "\n",
        "* scatter plot\n",
        "\n",
        "**Observations**\n",
        "\n",
        "The scatter plot shows that in general, larger loans have longer duration of repayment. Cases where large loans are given with short repayment period have turned out to be bad loans. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(y=df.credit_amount, x=df.duration, hue=df.target, s=100, );"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425462075
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.3 Exploration of categorical variables**\n",
        "\n",
        "**Relationship between credit risk and skills of loan applicant**\n",
        "\n",
        "* Bar-graph\n",
        "\n",
        "**Observations**\n",
        "\n",
        "The graph shows that candidates who are umeployed/unskilled pose a high risk"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('job')['target'].value_counts().unstack(level=1).plot.barh(stacked=True, figsize=(10, 6))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425462283
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.4 Relationship between credit amount and duration of the loan**\n",
        "\n",
        "* Line graph\n",
        "\n",
        "**Observation**\n",
        "\n",
        "There is a linear relationship between the credit amount and duration. The larger the credit amount, the longer is the repayment duration."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lineplot(data=df, x='duration', y='credit_amount', hue='target', palette='deep');"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425463739
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.5 Relationship between the most valuable asset of the candidate and the credit amount, credit risk**\n",
        "\n",
        "* stacked bar chart\n",
        "* scatter plot\n",
        "\n",
        "The categorical coding used in the graphs is :\n",
        "\n",
        "* A121 : real estate\n",
        "* A122 : if not A121 : building society savings agreement/life insurance\n",
        "* A123 : if not A121/A122 : car or other, not in attribute 6\n",
        "* A124 : unknown / no property\n",
        "\n",
        "**Observations**\n",
        "\n",
        "The graphs show that people with real estate assets are very risky."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('most_valuable_asset')['target'].value_counts().unstack(level=1).plot.barh(stacked=True, figsize=(10, 6))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425463916
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(y=df.credit_amount, \n",
        "                x=df.most_valuable_asset, \n",
        "                hue=df.target, \n",
        "                s=100, \n",
        "                );"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425464243
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Encode categorical variables\n",
        "\n",
        "Most machine learning models cannot deal with categorical variables. So we need to encode the 13 categorical variables that we have in the german dataset. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of unique classes in each object column\n",
        "df.select_dtypes('object').apply(pd.Series.nunique, axis = 0)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425464362
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have categorical variables with 2 to 10 categories. We go for Label encoding for variables with only two categories where as for variables with more than two categories, we go for one-hot encoding. In label encoding, we assign each unique category in a categorical variable with an integer. No new columns are created. In one-hot encoding, we create a new column for each unique category in a categorical variable. The only downside to one-hot encoding is that the number of features (dimensions of the data) can explode with categorical variables with many categories. To deal with this, we can perform one-hot encoding followed by PCA or other dimensionality reduction methods to reduce the number of dimensions (while still trying to preserve information).\n",
        "\n",
        "For label encoding, we use the Scikit-Learn LabelEncoder and for one-hot encoding, the pandas get_dummies(df) function."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn preprocessing for dealing with categorical variables\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "le_count = 0\n",
        "\n",
        "for col in df:\n",
        "    if df[col].dtype == 'object':\n",
        "        if len(list(df[col].unique())) <= 2:\n",
        "            le.fit(df[col])\n",
        "            df[col] = le.transform(df[col])\n",
        "            le_count += 1\n",
        "            \n",
        "print('%d columns were label encoded.' % le_count)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425464469
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding of categorical variables\n",
        "df = pd.get_dummies(df)\n",
        "\n",
        "print('Encoded Features shape: ', df.shape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425464579
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have encoded the variables, let's continue with the EDA. \n",
        "\n",
        "**4.1 Correlation between the variables**\n",
        "\n",
        "Let's look at correlations between the features and the target using Pearson correlation coefficient. In this case, a postive correlation represnets correlation with credit default while a negative correlation represnets correlation with credit repayment.\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "Positive correlation:\n",
        "* People with checking accounts with a negative balance (`account_bal_A11`) are likely to default the loan. \n",
        "\n",
        "* Longer duration loans (`duration`) tends to be defaulted.\n",
        "\n",
        "Negative correlation:\n",
        "\n",
        "* People with no checking account (`account_bal_A14`) are likely to repay the loan."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find correlations with the target and sort\n",
        "correlations = df.corr()['target'].sort_values()\n",
        "\n",
        "# Display correlations\n",
        "print('Most Positive Correlations:\\n', correlations.tail(15))\n",
        "print('\\nMost Negative Correlations:\\n', correlations.head(15))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425464889
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the significantly correlated variables\n",
        "corr_data = df[['target', 'account_bal_neg_bal','duration','account_bal_no_acc']]\n",
        "corr_data_corrs = corr_data.corr()\n",
        "\n",
        "\n",
        "# Heatmap of correlations\n",
        "sns.heatmap(corr_data_corrs,  vmin = -0.25, annot = True, vmax = 0.6)\n",
        "plt.title('Correlation Heatmap');"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425466226
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Feature engineering\n",
        "Feature engineering refers to creating most useful features out of the data. This represents one of the patterns in machine learning: feature engineering has a greater return on investment than model building and hyperparameter tuning. [[Source]](https://www.featurelabs.com/blog/secret-to-data-science-success/)\n",
        "\n",
        "Feature engineering refers to a geneal process and can involve both **feature construction**: adding new features from the existing data, and **feature selection**: choosing only the most important features or other methods of dimensionality reduction. There are many techniques we can use to both create features and select features.\n",
        "\n",
        "For this problem, we will try to construct polynomial features.\n",
        "\n",
        "### Polynomial Features\n",
        "Here, we find interactions between the significant features. The correlation between the interaction features are target are checked.If the interaction features are found to have greater correlation with the target compared to the original features, they are included in the machine learning model as they can help the model learn better. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a new dataframe for polynomial features\n",
        "poly_features = df[['duration','account_bal_neg_bal','account_bal_no_acc']]\n",
        "poly_target=df['target']\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "                                  \n",
        "# Create the polynomial object with specified degree\n",
        "poly_transformer = PolynomialFeatures(degree = 2)\n",
        "# Train the polynomial features\n",
        "poly_transformer.fit(poly_features)\n",
        "\n",
        "# Transform the features\n",
        "poly_features = poly_transformer.transform(poly_features)\n",
        "print('Polynomial Features shape: ', poly_features.shape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425466842
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates a considerable number of new features. To get the names we have to use the polynomial features `get_feature_names` method."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poly_transformer.get_feature_names(input_features = ['duration','account_bal_neg_bal','account_bal_no_acc'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425467884
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can see whether any of these new features are correlated with the target."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe for polynomial features \n",
        "poly_features = pd.DataFrame(\n",
        "    poly_features, columns = poly_transformer.get_feature_names(\n",
        "        ['duration','account_bal_neg_bal','account_bal_no_acc']))\n",
        "\n",
        "# Add in the target\n",
        "poly_features['target'] = poly_target\n",
        "\n",
        "# Find the correlations with the target\n",
        "poly_corrs = poly_features.corr()['target'].sort_values()\n",
        "\n",
        "# Display the correlations\n",
        "poly_corrs"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425469095
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the new variables have a greater (in terms of absolute magnitude) correlation with the target than the original features. \n",
        "We will add these features to a copy of the german dataset and then evaluate models with and without the features. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(poly_features)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425469894
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# deleting duplicate columns in poly_features\n",
        "\n",
        "for i in list(poly_features.columns):\n",
        "  for j in list(df.columns):\n",
        "    if (i==j):\n",
        "      poly_features.drop(labels=i, axis=1, inplace=True)\n",
        "\n",
        "poly_features.drop(labels='1', axis=1, inplace=True)\n",
        "list(poly_features)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425593180
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print shape of original german_df\n",
        "print('Original features shape: ', df.shape)\n",
        "\n",
        "# Merge polnomial features into the dataframe\n",
        "df_poly = df.merge(poly_features, left_index=True, right_index=True, how = 'left')\n",
        "\n",
        "# Print out the new shapes\n",
        "print('Merged polynomial features shape: ', df_poly.shape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425628767
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_poly.isna().any().any()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425646076
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Data split to train and test datasets"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x, y = df.drop('target', axis=1), df['target']\n",
        "x.shape, y.shape\n",
        "\n",
        "x_train, x_test, y_train, y_test= train_test_split(x,y, test_size=.2, random_state=42)\n",
        "x_train.shape, x_test.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425697950
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's normalize the features to prevent undue influence in the model.\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# scale each feature to 0-1\n",
        "scaler = MinMaxScaler(feature_range = (0, 1))\n",
        "\n",
        "# fit on features dataset\n",
        "scaler.fit(x_train)\n",
        "scaler.fit(x_test)\n",
        "x_train= scaler.transform(x_train)\n",
        "x_test= scaler.transform(x_test)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425743000
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Models\n",
        "\n",
        "**Evaluation criteria**\n",
        "\n",
        "Let's have a look at the different options available.\n",
        "\n",
        "|Evaluation criteria| Description\n",
        "|:---|---\n",
        "|Accuracy| (true positive+ true negative) / total obs\n",
        "|Precision| true positive/ total predicted positive\n",
        "|Recall| true positive/ total actual positive\n",
        "|F1 | 2* precision * recall / (precision + recall)\n",
        "|AUC ROC| Area Under ROC Curve  (TPR Vs. FPR for all classification thresholds)\n",
        "\n",
        "* Accuracy: The german dataset is an imbalanced dataset. Accuracy would give a high score by predicting the majority class but would fail to predict the minority class, which is the defaulters. Hence, this is not a suitable metric for this dataset.\n",
        "\n",
        "* Precision: Precision is a good metric when the costs of false positive is high. Example, email spam detection.\n",
        "\n",
        "* Recall: This metric is suitable when the costs of false negative is high. Example, predicting a defulter as not defaulter. This costs huge loss for the bank. Hence, this is a suitable metric for our case.\n",
        "\n",
        "* F1: measure of both precision and recall.\n",
        "\n",
        "* AUC ROC: It is the plot of TPR vs FPR. All other criteria discussed here assumes 0.5 as the decision threshold for the classification. However, it maynot be always true. The AUC helps us evaluate the performance of the model for all classification thresholds. The higher the value of the AUC metric, the better the model.\n",
        " * True positive rate (TPR) = TP/ Total actual positive\n",
        " * False positive rate (FPR) = FP/ Total actual negative\n",
        "\n",
        "We will use Recall and AUC ROC as evaluation metric."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y.value_counts(normalize=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425776611
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It means that the baseline accuracy is 70%, ie, even if we classify all the samples as defaulters, we will be 70% accurate. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Models without tuning**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages, functions, and classes\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, recall_score, classification_report\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425820875
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare models\n",
        "models = []\n",
        "models.append(('DT', DecisionTreeClassifier(random_state=42)))\n",
        "models.append(('LR', LogisticRegression(random_state=42)))\n",
        "models.append(('RF', RandomForestClassifier(random_state=42)))\n",
        "models.append(('NB', GaussianNB())) \n",
        "models.append(('XGB', XGBClassifier(random_state=42)))\n",
        "models.append(('KNN', KNeighborsClassifier())) \n",
        "models.append(('SVM', SVC(gamma='auto',random_state=42)))\n",
        "'''\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "'''\n",
        "\n",
        "# evaluate each model in turn\n",
        "results_recall = []\n",
        "results_roc_auc= []\n",
        "names = []\n",
        "# recall= tp/ (tp+fn). Best value=1, worst value=0\n",
        "scoring = ['recall', 'roc_auc']\n",
        "\n",
        "for name, model in models:\n",
        "        # split dataset into k folds. use one fold for validation and remaining k-1 folds for training\n",
        "        skf= StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "        # Evaluate a score by cross-validation. Returns array of scores of the model for each run of the cross validation.\n",
        "        #cv_results = cross_val_score(model, x_train, y_train, cv=skf, scoring=scoring)\n",
        "        cv_results = cross_validate(model, x_train, y_train, cv=skf, scoring=scoring)\n",
        "        results_recall.append(cv_results['test_recall'])\n",
        "        results_roc_auc.append(cv_results['test_roc_auc'])\n",
        "        names.append(name)\n",
        "        msg = \"%s- recall:%f roc_auc:%f\" % (name, cv_results['test_recall'].mean(),cv_results['test_roc_auc'].mean())\n",
        "        print(msg)\n",
        "        \n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure(figsize=(11,6))\n",
        "fig.suptitle('Recall scoring Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results_recall, showmeans=True)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show();\n",
        "\n",
        "fig = plt.figure(figsize=(11,6))\n",
        "fig.suptitle('AUC scoring Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results_roc_auc, showmeans=True)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show();\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425835147
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# boxplot algorithm comparison\n",
        "fig = plt.figure(figsize=(11,6))\n",
        "fig.suptitle('Recall scoring Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results_recall, showmeans=True)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show();\n",
        "\n",
        "fig = plt.figure(figsize=(11,6))\n",
        "fig.suptitle('AUC scoring Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results_roc_auc, showmeans=True)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show();"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671431130389
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gaussian NB model has the highest `roc_auc` score. However, Logistic regression, Randon forests, XGBoost and SVM bas better AUC score than Gaussian NB. Now let us tune hyperparameters for each of these models."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671426185950
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_roc_auc"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671426274147
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC AUC plot\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "results_table = pd.DataFrame(columns = ['models', 'fpr','tpr','auc'])\n",
        "predictions = {'LR': y_pred_log, 'SVC': y_pred_svc, 'NB': y_pred_nb, 'XGB': y_pred_xgb, 'Stacked': final_predictions}\n",
        "\n",
        "\n",
        "for i in results_table.index:\n",
        "    plt.plot(results_table.loc[i]['fpr'], \n",
        "             results_table.loc[i]['tpr'], \n",
        "             label = \"{}, AUC={:.3f}\".format(i, results_table.loc[i]['auc']))\n",
        "\n",
        "plt.plot([0,1], [0,1], color = 'black', linestyle = '--')\n",
        "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
        "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
        "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
        "plt.legend(prop = {'size':13}, loc = 'lower right')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671426113823
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 Logistic regression"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_models_test=[]\n",
        "tuned_models_train=[]\n",
        "\n",
        "# Create the model with the specified regularization parameter\n",
        "log_reg = LogisticRegression(C = 0.0001, random_state=42)\n",
        "\n",
        "# Train on the training data\n",
        "log_reg.fit(x_train, y_train)\n",
        "\n",
        "# Evaluate on test dataset\n",
        "recall_test= recall_score(y_test,log_reg.predict(x_test))\n",
        "roc_test=roc_auc_score(y_test,log_reg.predict_proba(x_test)[:, 1])\n",
        "print('LR',' recall_test:', round(recall_test,2),' auc_roc_test:', round(roc_test,2))\n",
        "tuned_models_test.append(('LR',' recall_test:', round(recall_test,2),' auc_roc_test:', round(roc_test,2)))\n",
        "\n",
        "# Evaluate on train dataset\n",
        "roc_train= cross_val_score(log_reg, x_train, y_train, cv=skf, scoring='roc_auc').mean()\n",
        "recall_train= cross_val_score(log_reg, x_train, y_train, cv=skf, scoring='recall').mean()\n",
        "print('LR',' recall_train:', round(recall_train,2),' auc_roc_train:', round(roc_train,2))\n",
        "tuned_models_train.append(('LR',' recall_train:', round(recall_train,2),' auc_roc_train:', round(roc_train,2)))\n",
        "print(classification_report(y_test, log_reg.predict(x_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425899700
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Generate ROC curve values: fpr, tpr, thresholds\n",
        "fpr, tpr, thresholds = roc_curve(y_test, log_reg)\n",
        "# Plot ROC curve\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425940491
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "model_xg = XGBClassifier(random_state=42)\n",
        "model_xg.fit(x_train, y_train)\n",
        "#evaluate\n",
        "print('Train accuracy:', cross_val_score(model_xg, x_train, y_train, cv=skf).mean())\n",
        "print('Test accuracy:', accuracy_score(y_test, model_xg.predict(x_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671425994732
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGboost"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "model_xg = XGBClassifier(random_state=42)\n",
        "model_xg.fit(x_train, y_train)\n",
        "#evaluate\n",
        "print('Train accuracy:', cross_val_score(model_xg, x_train, y_train, cv=skf).mean())\n",
        "print('Test accuracy:', accuracy_score(y_test, model_xg.predict(x_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671426030371
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the set of parameters for exhaustive search and fit \n",
        "parameters = {'max_features': [7, 10, 16, 18], \n",
        "              'min_samples_leaf': [1, 3, 5, 7], \n",
        "              'max_depth': [15, 20, 24, 27]}\n",
        "rf = XGBClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
        "gcv = GridSearchCV(rf, parameters, n_jobs=-1, cv=skf, verbose=1)\n",
        "gcv.fit(x_train, y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1671426041699
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}